\section{Introduction}

In the previous work with \textsc{Alpine} and \textsc{Palm} we hypothesized that enabling both models to run together and combine their votes would yield the most accurate and agreed-upon classification results. The results of the multi-embedding experiments in this work proved this to be more accurate. Multiple classifier systems (MCS) are ensembles and are widely used in pattern recognition applications and recognized as more effective than any single embedding or classifier. There are at least three reasons identified by Dietterich as to why multi-classifier approaches perform well~\cite{dietterich2000ensemble}:

\begin{itemize}
    \item Statistically, there is a set of $H$ hypotheses for which the learning algorithm is performing a search for the best hypothesis. The risk of choosing the wrong classifier is reduced when using multiple for unseen data.
    \item Computationally, optimal training is an NP-hard problem. Because the optimum depends on the starting point, the optimal learning algorithm may be different. By using an ensemble, a better approximation of the unknown function may be obtained.
    \item Representationally, the weighted sums of hypotheses from $H$ allows for the expanding of space of representable functions. Simply put, the more embeddings we have, the more features, and the more ways to represent and compare data.
\end{itemize}

In addition to multiple classifiers, in the workflow process using multiple types of embeddings has proven more effective in several recent, real systems than any single approach~\cite{tajaddodianfar2020texception, instruction2vec, duarte2019semi, yang2022, ayoade2020evolving, palau2020dns, kishioka2018, Boyaci2022, glass}.

As we have seen in previous chapters, each model unveils different hidden representations which are appropriate for different classification problems and contexts. In the real network environment, these classification problems are not isolated. Traffic may need to be distinguished between encrypted and plaintext, for example, and then protocols identified. Then, encrypted traffic may be profiled, or the plaintext traffic characterized by embedding for user fingerprints. Thus, a combined approach or toolkit is apt for the many kinds of problems real world network analysts face.

To meet this need, we propose \textsc{Forager}, a combination of data mining and hidden representation learning approaches to deep packet inspection and network traffic classification. This highly configurable toolkit includes the ability to extract and transform header features into locality-sensitive hashes indexed in an LSHForest using the \textsc{Alpine} technique. Payloads may be combinatorally analyzed using either the \textsc{Palm}, \textsc{Maple}, or \textsc{Date} approaches, or a combination of votes from these models. By considering the data from multiple angles, we achieve results of higher accuracy and a much greater understanding of the network traffic than other state-of-the-art systems.

To illustrate the capability of \textsc{Forager} and its diversity of traffic applications, we performed a case study on profiling the traffic on port 443. Due to the rise of encryption and its standard usage for Hypertext Transfer Protocol Secure (HTTPS) encrypted traffic, port 443 is often left un-monitored by packet inspection on large-scale surveillance systems or default-allowed by firewall software. While the majority of internet traffic is now safely secured behind transport layer security, there are threat actors who have found ways to utilize port 443 as a covert data channel for surveillance and firewall evasion, malware transport, data exfiltration, and nefarious activity under the guise of internet anonymity. For increased security and surveillance, it is necessary to be able to filter legitimate, HTTPS traffic from illicit activity on this port. We propose using \textsc{Forager}, our network traffic classification and profiling toolkit, to dissect this traffic stream for hidden content. Using \textsc{Forager} and its individual models, we are able to extract plaintext and compressed traffic from encrypted streams with high accuracy, profile Tor-based, VPN-based, and encrypted traffic streams by application and data type, and identify malicious instances of particular protocols designated to run over HTTPS. Our models combine several approaches to hidden feature extraction from packets via spatial representation learning to precisely and efficiently classify packets, fortifying network security while still preserving user privacy through this crucial gateway.
