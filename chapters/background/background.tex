This section will introduce previous work related to deep packet inspection and the progression toward  machine learning for network traffic classification. Related work toward specific techniques will be further discussed in the ``Previous Work'' subsections of subsequent chapters.

As a disclaimer to this section and a warning to researchers exposed to other works in this problem area, we emphasize that not all network traffic classification systems are comparable to one another. Systems can classify the same data using different input features or into different classes. Choorod et al~\cite{choorod2022tor} and architects of DIDarknet~\cite{didarknet} classify the same ISCX Tor/non-Tor dataset in different ways. Choorod et al focuses solely on darknet detection, whereas DIDarknet further explores traffic profiling by application and traffic type. This dataset along with the ISCX VPN/non-VPN dataset are used by many works, but different systems require certain input features. Not all systems are applicable to all network environments due to classification capability and system requirements such as processing speed or memory usage. Depending on the implementation, a trade-off to prioritize accuracy over resource utilization may not always be the right choice (or vice versa). It may be essential to prioritize accuracy if the system is capable of storing and processing the amount of data at an acceptable rate. Having multiple systems capable of using different features is a more practical approach to the network traffic classification problem because it is unlikely one solution will work equally as well for multiple problems, and many real world applications may not afford all the features that one system requires over another.


\section{Deep Packet Inspection}
Deep packet inspection is the process of analyzing traffic data as it comes across the network. Packet headers contain information which can tell what type of application layer data is being transported in the packet. Furthermore, packet payload contents may be inspected for signatures matching protocols, applications, users, or other content related to a particular class. More recently, systems have explored data transformation such as embeddings or statistical analysis on raw packet data in order to generate hidden features for representation learning-based DPI.

\subsection{Port-based Identification}
IANA, the Internet Assign Number Authority, requires default ports for certain protocols in standard traffic~\cite{IANA}. Classifying traffic based on port number is increasingly unreliable due to non-standard port usage and dynamic port translation. Applications or users may ignore protocol standards for both legitimate and illegal reasons. For example, a network administrator may choose to load-balance traffic to a different port for resource allocation. On the other hand, criminal activities could be conducted on a non-standard port for obfuscation purposes. Sometimes, benign IoT traffic is sent over a port like 443 or 80, as well~\cite{charyyev2020iot}. Individuals can also design applications which do not follow the standard; a webmaster can easily host HTTP content on port 8080 rather than 80. Skype is known to use Web TCP to listen on port 80 although it is not HTTP traffic \cite{Freire}. Any peer-to-peer architecture also has the potential to operate on any range of ports, including ports intended for other applications \cite{Karagiannis}.

Some protocols or traffic sessions may dynamically configure their ports from a given range; this also poses a problem to port-based identification in a single-packet context. Network Address Port Translation (NAPT) is a process that sits between the sender and the destination, allowing multiple computers on a network to use one global IP address. If a sender wants to listen over a specific port for a response from the Internet and that port is not available within the NAPT set, the port will be translated to an unused number and mapped appropriately within the translation table. Therefore, when the destination is sending information back to the sender, the destination port will match what the NAPT set, not the port specified by the sender \cite{Smith}.

\subsection{Payload-based Identification}
Because port-based identification became inaccurate in real world applications, researchers moved toward inspecting other parts of the packet, particularly the payload. In shallow packet inspection, we focus on what information can be extracted from the physical, data link, network, and transport layers of packet encapsulation as described by the OSI model~\cite{OSI}. This is then extended into deep packet inspection which analyzes the session, presentation, and application layers of a packet.

DPI can be rendered ineffective by encryption protocols like TLS, but is still used today for plaintext traffic~\cite{ZHAO202122}. While much of the Internet's traffic today is encrypted, there are still applications for plaintext analysis afforded by deep packet inspection. Many applications will send control, setup, and session management messages in the clear, which may provide contextual information or protocol type indication~\cite{Hasanzadeh, Ogudo, Zhang}. Public Wi-Fi access points can also pass unencrypted traffic~\cite{Maimon}. Internet of Things (IoT) devices have rapidly permeated our society and introduced new protocols and formats, yet their growth currently outpaces the security regulations for them. Popular market devices like Google Home and Amazon Echo do not set encryption standards, have privacy policies in place, or are yet regulated by cybersecurity laws and will send and store data messages in plaintext \cite{wood2017cleartext, Capellupo, WangYong}. Older systems such as those found in factory SCADA and PLC networks may also not support encryption \cite{Malaka} and thus may be inspected.

Even in encrypted payloads, researchers have found that signatures can still exist. Despite end-to-end encryption in Skype, even in its signaling messages, Bernaille et al~\cite{Bernaille} found that a specific 15-byte sequence always occurred at the beginning of a Skype login server (LS) message which could be used as a signature for application detection. Shallow DPI can also be used to analyze public headers in packets; HeaderHunter~\cite{HeaderHunter} utilizes DPI pattern matching on packet metadata found in the headers of encrypted traffic, specifically packet size, direction, and TCP information. Unfortunately, this and other systems~\cite{Moore2013DiscriminatorsFU, Roughan} require a full session capture in order to classify packets after the fact, so are not applicable to single-packet classification. These examples and their shortcomings further assert the relevance and potential of our system and payload-based identification as a whole.

\subsection{Flow-based Identification}

There are other heuristics from protocol flows which developers and researchers may derive further information or hidden features from. These statistics-based identification methods typically focus on mean, minimum, and maximum of packet sizes, the number of packets seen in a given exchange, burst rates, the time between packets, TCP flags, IP/port numbers, flow duration, and so forth~\cite{Moore2013DiscriminatorsFU, ZHAO202122, Paxson}.
In the existing literature, most use machine-learning or statistics techniques that study time and flow-based features of packet streams~\cite{Salman, Cao, Lim, LiZ, Song2019, iscx-vpn-paper, iscx-tor-paper}. Some mechanisms require flow-based or time-series features, which means capturing and analyzing several packets in a flow~\cite{onlyheader, zhou2018encrypted}, or in some cases the entire session~\cite{perera2017comparison, deeppacket, panchenko2011website, amaral2016machine, cao2014survey, ibrahim2016internet, fan2017investigation, sun2018internet}. The need to capture or buffer entire flows for classification does not scale well to large systems with memory or CPU constraints. Furthermore, it delays classification in real-time applications which may be trying to dynamically process the data. There is also no guarantee to receive the whole stream if capture begins in the middle of the session or there is data corruption. In our work as in some others, we focus on per-packet classification. In this scenario, we propose solutions which require only a single packet at any point in the flow for classification. We do not feed forward any information to the next classification or record any statistics about the packets over time or between arrivals. While this reduces the number of possible features and in some cases accuracy on public datasets, this is a constraint of the problem scenario we are considering in this work.

\section{Network Traffic Classification}

Common substrings~\cite{sigbox} or features like packet statistics can be extracted and used to train and make informed decisions in machine learning-based models. Quality of Service requirements and adaptive streaming features have been extracted to classify video streams using a Naive Bayes algorithm~\cite{DIAS2019143} or state vector machine (SVM)~\cite{LiZ, Cao}. These potentially have significant drawbacks such as high computational complexity, high-retraining time, and reduced performance compared to other models like K-Nearest Neighbors~\cite{Salman}. C4.5 and other decision tree methods have proven performant when used to classify traffic on large datasets, as well~\cite{Yuan, iscx-vpn-paper}. Stateless applications of neural networks have also been able to achieve greater accuracy than the C4.5 approach~\cite{deeppacket}. Similarly, word embeddings have also become practical in the stateless context with Packet2Vec \cite{packet2vec}.
