This section will introduce previous work related to deep packet inspection and the progression toward  machine learning for network traffic classification. Related work toward specific techniques will be further discussed in the ``Previous Work'' subsections of subsequent chapters.

Not all research publications related to encrypted traffic classification can be fairly compared to one another; systems may classify the same data different ways. For example, DIDarknet~\cite{didarknet} attempts to classify the same ISCX Tor/non-Tor dataset as Choorod et al~\cite{choorod2022tor}, but DIDarknet profiles applications in the Tor traffic and Choorod et al's work focuses on darknet detection (only Tor or non-Tor). Many works use the ISCX VPN/non-VPN and Tor-non/Tor datasets or their original PCAPs and achieve higher accuracy and F1-scores than one another in various scenarios. These mechanisms require time-series based or flow features, which in real system application means capturing and analysis large portions of or entire flows in order to classify~\cite{perera2017comparison, deeppacket, panchenko2011website, amaral2016machine, cao2014survey, ibrahim2016internet, fan2017investigation, sun2018internet, iscx-tor-paper, iscx-vpn-paper}. Some systems have been able to cull this down to a few of the first packets of a connection~\cite{onlyheader, zhou2018encrypted}. For a forensic analysis on a small dataset this may be sufficient; however, this does not scale to live capture systems. If the monitored network is sufficiently large enough (for example, on the order of terabytes of data per second), and traffic is expected to be classified and then processed by a follow-on application in real time, it may not be practical to buffer that amount of data and maintain the complexity of that many flows. In our threat model, we choose instead to prioritize making classification using only a single packet from any point in the overall traffic flow. We do not feed forward any information to the next classification or record any statistics about the packets over time or between arrivals. This is an implementation choice that focuses on performance optimization and achieving line rate as a single packet classification would lead to higher throughput as there is less strain on system resources and faster processing time without buffering. This trade-off may not always be the right choice depending on the real-world scenario. In some cases the priority may be accuracy and/or the system has resources capable of storing and processing the amount of data, or the amount of data many be contained. Having multiple systems capable of using different features is a more practical approach to the network traffic classification problem because it is unlikely one solution will work equally as well for multiple problems, and many real world applications may not afford all the features that one system requires over another.

\section{Deep Packet Inspection}
Deep packet inspection is the process of analyzing traffic data as it comes across the network. Packet headers contain information which can tell what type of application layer data is being transported in the packet. Furthermore, packet payload contents may be inspected for signatures matching protocols, applications, users, or other classes.

\subsection{Port-based Identification}
The Internet Assign Number Authority (IANA) requires that certain protocols be registered to certain ports \cite{IANA}. In theory, this would allow traffic to be analyzed strictly at the transport layer to classify the packet; however, this technique has become increasingly unreliable due to nonstandard port usage and port translation. Additionally, some applications or users may choose to ignore protocol standards in implementations or design new applications which do not follow the standard. For example, a webmaster can easily host HTTP content on port 8080 rather than 80. Skype is known to use Web TCP to listen on port 80 although it is not HTTP traffic \cite{Freire}. Any peer-to-peer architecture also has the potential to operate on any range of ports, including ports intended for other applications \cite{Karagiannis}.

Dynamic port numbers also pose a problem to port-based identification. Network Address Port Translation (NAPT) is a process that sits between the sender and the destination, allowing multiple computers on a network to use one global IP address. If a sender wants to listen over a specific port for a response from the internet and that port is not available within the NAPT set, the port will be translated to an unused number and mapped appropriately within the translation table. Therefore, when the destination is sending information back to the sender, the destination port will match what the NAPT set, not the port specified by the sender \cite{Smith}.

\subsection{Payload-based Identification}
Following noticeable decline in port-based identification accuracy, researchers began inspecting packet contents themselves for classification. Shallow packet inspection focuses on what can be derived from the physical, data link, network, and transport layers of packet encapsulation as described by the OSI model~\cite{OSI}. This then extended into deep packet inspection which studies the session, presentation, and application layers of a packet in order to derive the packet's content.

The increased usage of encryption protocols like TLS can render DPI ineffective \cite{ZHAO202122}, but it remains an efficient approach for plain text traffic. Shallow DPI can also be used to analyze public headers in packets. Many applications will send control, setup, and session management messages in the clear, which may provide contextual information or protocol type indication \cite{Hasanzadeh, Ogudo, Zhang}. Additionally, public Wi-Fi access points may also pass unencrypted traffic which sniffers can then decode and analyze \cite{Maimon}. The expansion of Internet of Things (IoT) devices has caused rapid growth in new protocols and formats which currently outpaces the security regulations for them. Many of these devices like Google Home and Amazon Echo do not set encryption standards, have privacy policies in place, or are yet regulated by cybersecurity laws and will send and store data messages in plain text \cite{wood2017cleartext, Capellupo, WangYong}. Older systems such as those found in factory SCADA and PLC networks may also not support encryption \cite{Malaka} and thus may be inspected.

Research has shown that for some applications, encrypted payloads still hold common data sequences which can be used for signatures. For example, Bernaille et al \cite{Bernaille} found that a specific 15-byte sequence always occurred at the beginning of a Skype login server (LS) message, which could be used as a signature for application detection despite Skype being end-to-end encrypted even in its signaling messages. The HeaderHunter system \cite{HeaderHunter} utilizes DPI pattern matching on packet metadata found in the headers of encrypted traffic, specifically packet size, direction, and TCP information. This and other systems \cite{Moore2013DiscriminatorsFU, Roughan} require a full session capture in order to classify packets after the fact, so are not applicable to single-packet classification. These examples and their shortcomings further assert the relevance and potential of our system and payload-based identification as a whole. \par

\subsection{Flow-based Identification}
Developers have also examined using other heuristics from protocol flows to derive knowledge about packets and their protocols. These statistics-based identification methods typically focus on mean, minimum, and maximum of packet sizes, the number of packets seen in a given exchange, the time between packets, burst rates, IP/port numbers, TCP flags, flow duration, and so forth \cite{Moore2013DiscriminatorsFU, ZHAO202122, Paxson}. In the existing literature, most use machine-learning or statistics techniques that study time and flow-based features of packet streams~\cite{Salman, Cao, Lim, LiZ, Song2019, iscx-vpn-paper, iscx-tor-paper}; however, in real-time network engineers may not be able to wait for or buffer entire packet streams before they can classify packets and send them to follow-on processing. In forensics, analysts may not have access to full streams. Many machine learning methods are not applicable for stateless packet inspection as they require time-based or flow-based features. Thus, per-packet solutions for both encrypted and non-encrypted data are a pressing research need regardless of flow-based solutions.

\section{Network Traffic Classification}
A machine-learning based approached can be used to train models to make informed decisions based on extracted features like packet statistics or common substrings \cite{sigbox}. For example, video streams can be classified using a Naive Bayes approach and extracting features related to Quality of Service requirements and adaptive streaming \cite{DIAS2019143}. SVM has also been widely studied for this purpose \cite{LiZ, Cao}, but has significant drawbacks such as high computational complexity, high-retraining time, and reduced performance compared to other models like K-Nearest Neighbors \cite{Salman}. Decision tree classification methods have also been used to classify traffic with high performance on large data sets; C4.5 is one of the most utilized methods used in this domain \cite{Yuan, iscx-vpn-paper}. In recent research, neural networks have also been adapted to solve the classification problem with greater success when compared to C4.5 \cite{deeppacket}. Word embeddings have also become a practical approach even in the stateless context with Packet2Vec \cite{packet2vec}.
